{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignemnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement a simple approach to cluster the listings data into similar items\n",
    "clusters that can be used in this way: If the items A and B are part of the\n",
    "same cluster it is reasonable to recommend B to a user that is viewing or has\n",
    "viewed A. Feel free to use the category information that sellers have used to\n",
    "classify their listings in any way.\n",
    "\n",
    "\n",
    "* How do you evaluate the quality of your results? \n",
    "\n",
    "\n",
    "* How does it compare to a naive approach that takes random listings from the same category?\n",
    "\n",
    "\n",
    "* What are possible shortcomings and extensions of your implementation?\n",
    "\n",
    "\n",
    "* How are newly listed (unseen) listings assigned to your clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cluster size: 50 ( seems reasonable for a pool of items to recommend )\n",
    "\n",
    "\n",
    "* Broad groupings\n",
    "    - L2 categories are large enough to be used as a first filter\n",
    "    - A separate clustering is run within each L2 category\n",
    "    \n",
    "\n",
    "* Similarity features\n",
    "    - TF-IDF on title+description\n",
    "    - price\n",
    "    - geodistance\n",
    "\n",
    "\n",
    "* Clustering algorithm\n",
    "    - Agglomerative\n",
    "        - admits custom distance\n",
    "        - allows to input desired n_clusters\n",
    "        \n",
    "        Best choice, according to http://scikit-learn.org/stable/modules/clustering.html\n",
    "\n",
    "\n",
    "* Processing\n",
    "    - lemmatization, lowercase\n",
    "\n",
    "\n",
    "* New items\n",
    "    - Update distance matrix\n",
    "    - We can use KNN to assign new cluster\n",
    "    - Refit clusters sporadically, only when there's a large enough number of new items\n",
    "\n",
    "\n",
    "* Evaluation\n",
    "    - Ideally, an A/B test were we track variation of metrics like clicks, conversion, revenue\n",
    "    - for now\n",
    "        - explore sample\n",
    "        - some cluster quality metric?\n",
    "\n",
    "\n",
    "* Main shortcomings and posible solutions\n",
    "    - AgglomerativeClustering doesn't scale well for larger data, unless a connectivity matrix is provided. K-Means is more scalable ( even more if we use MiniBatch K-Means ) but it is limited to use the Euclidean distance and doesn't accept a custom distance metric. There is a variant (K-medoids) which we could use in this case.  \n",
    "    - TFIDF captures a too strict notion of similarity, where basically there have to be many common tokens between two given texts for them to be considered similar. There is no notion of semantic relatedness between tokens. We could ammend this by fitting an LDA model and transforming TFIDF vectors to vectors of LDA topic-scores. Another option, given enough data, would be to fit some word2vec model and then use Word Mover's Distance to measure similarity between texts.\n",
    "\n",
    "    \n",
    "\n",
    "* Extensions and improvements\n",
    "    - use search keyword popularities to somehow weight the TFIDF scores of terms.\n",
    "    - use L3 as parent clusters when large enough to split. Let's say, more than 70 items ( mostly cars ).\n",
    "    - Incremental clustering ( IHAC ) https://github.com/frnsys/galaxy\n",
    "    - Improve similarity computation \n",
    "        https://blog.booking.com/k-nearest-neighbours-from-slow-to-fast-thanks-to-math.html\n",
    "    - feature weights\n",
    "    - word2vec model\n",
    "    - Named Entity Recognition and POS tags\n",
    "    - Retrieval: rank items in cluster by similarity to seed item\n",
    "    - Parallelize frequency computations ( gensim )\n",
    "    - use MiniBatch K-means when doing it in scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
